---
phase: 08-python-companion
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - python/src/catune/_fista.py
  - python/src/catune/_io.py
  - python/src/catune/__init__.py
  - python/tests/test_fista.py
  - python/tests/test_io.py
  - python/tests/test_equivalence.py
autonomous: true

must_haves:
  truths:
    - "User can call run_deconvolution(traces, fs, tau_r, tau_d, lam) and get non-negative spike estimates"
    - "run_deconvolution produces results identical to the Rust/WASM solver within rtol=1e-10"
    - "User can call save_for_tuning(traces, fs, path) and get a .npy file plus _metadata.json sidecar"
    - "save_for_tuning output is loadable by CaTune's browser .npy parser"
    - "run_deconvolution handles both 1D (single trace) and 2D (multi-cell) input"
    - "All tests pass with pytest"
  artifacts:
    - path: "python/src/catune/_fista.py"
      provides: "FISTA deconvolution solver"
      exports: ["run_deconvolution"]
      min_lines: 60
    - path: "python/src/catune/_io.py"
      provides: "Data I/O functions"
      exports: ["save_for_tuning", "load_tuning_data"]
    - path: "python/src/catune/__init__.py"
      provides: "Complete public API"
      exports: ["build_kernel", "tau_to_ar2", "compute_lipschitz", "run_deconvolution", "save_for_tuning", "load_tuning_data"]
    - path: "python/tests/test_fista.py"
      provides: "FISTA solver tests"
      min_lines: 80
    - path: "python/tests/test_io.py"
      provides: "I/O round-trip tests"
      min_lines: 40
    - path: "python/tests/test_equivalence.py"
      provides: "End-to-end cross-language equivalence tests"
      min_lines: 30
  key_links:
    - from: "python/src/catune/_fista.py"
      to: "wasm/catune-solver/src/fista.rs"
      via: "identical FISTA algorithm with same variable names"
      pattern: "solution|solution_prev|t_fista|convolve"
    - from: "python/src/catune/_fista.py"
      to: "python/src/catune/_kernel.py"
      via: "import build_kernel, compute_lipschitz"
      pattern: "from \\._kernel import"
    - from: "python/src/catune/_io.py"
      to: "src/lib/npy-parser.ts"
      via: "compatible .npy format (Float64, C-contiguous, little-endian)"
      pattern: "np\\.save|np\\.ascontiguousarray"
    - from: "python/tests/test_equivalence.py"
      to: "python/src/catune/_fista.py"
      via: "run_deconvolution on synthetic traces, compare against reference"
      pattern: "assert_allclose.*rtol"
---

<objective>
Implement the FISTA deconvolution solver and I/O functions, completing the Python companion package.

Purpose: Ports the Rust FISTA algorithm to Python/NumPy for offline deconvolution (PYTH-02), implements save_for_tuning with JSON metadata sidecar for CaTune-compatible data export (PYTH-01), and verifies numerical equivalence between Python and Rust implementations via end-to-end tests.

Output: Complete catune Python package with run_deconvolution, save_for_tuning, load_tuning_data, and full test suite.
</objective>

<execution_context>
@/home/daharoni/.claude/get-shit-done/workflows/execute-plan.md
@/home/daharoni/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-python-companion/08-RESEARCH.md
@.planning/phases/08-python-companion/08-01-SUMMARY.md
@wasm/catune-solver/src/fista.rs
@wasm/catune-solver/src/lib.rs
@wasm/catune-solver/src/kernel.rs
@src/lib/export.ts
@src/lib/npy-parser.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement FISTA solver and I/O module</name>
  <files>
    python/src/catune/_fista.py
    python/src/catune/_io.py
    python/src/catune/__init__.py
  </files>
  <action>
1. **python/src/catune/_fista.py**: Direct port from `wasm/catune-solver/src/fista.rs`. Use the reference implementation from 08-RESEARCH.md as the starting point, but verify every detail against the Rust source:

   `run_deconvolution(traces, fs, tau_r, tau_d, lam, tolerance=1e-6, max_iters=2000) -> np.ndarray`:

   CRITICAL implementation details (verify each against fista.rs):

   a. **Forward convolution**: `np.convolve(solution_prev, kernel, 'full')[:n]` -- convolve at the EXTRAPOLATED point (solution_prev = y_k), NOT solution (x_k). See fista.rs line 38: `convolve_forward_from_prev()`.

   b. **Adjoint convolution**: `np.convolve(residual, kernel[::-1], 'full')[klen-1:klen-1+n]` -- NOTE the truncation is [klen-1:klen-1+n], NOT [:n]. This is the #1 pitfall from research.

   c. **Proximal step**: Save x_k (solution.copy()), then compute x_{k+1} from y_k:
      `solution = max(solution_prev - step_size * gradient - threshold, 0.0)`
      This matches fista.rs lines 56-59.

   d. **Objective at x_{k+1}**: Reconvolve using solution (NOT solution_prev):
      `recon_new = np.convolve(solution, kernel, 'full')[:n]`
      `objective = 0.5 * dot(res, res) + lam * sum(solution)`
      This matches fista.rs line 62: `convolve_forward()` (uses solution, not solution_prev).

   e. **Adaptive restart**: `if objective > prev_objective and iteration > 1: t_fista = 1.0`
      Match fista.rs line 67. Note: Rust checks `self.iteration > 1` where iteration was JUST incremented. In our Python loop starting at iteration=1, we check `iteration > 1` AFTER incrementing. Use the research implementation's approach where iteration starts at 1 in range(1, max_iters+1). The restart condition should fire when iteration > 1 (i.e., not on the very first iteration).

   f. **FISTA momentum**: Compute y_{k+1} = x_{k+1} + momentum*(x_{k+1} - x_k), then PROJECT to non-negative: `solution_prev = max(y_{k+1}, 0.0)`. This matches fista.rs lines 75-81.

   g. **Convergence check**: Skip first 5 iterations (`if iteration > 5`). Match fista.rs line 86. Since our loop starts at iteration=1, `iteration > 5` means the check begins at iteration 6, which matches Rust's behavior (Rust increments to 6 before the check at iteration > 5).

   h. **prev_objective assignment**: MUST come AFTER the convergence check, matching fista.rs line 93.

   i. **Multi-trace support**: Accept 1D or 2D input. If 1D, reshape to (1, n), process, return squeezed 1D result. Use np.atleast_2d and check ndim before return.

   Variable names MUST match Rust: solution, solution_prev, t_fista, step_size, threshold, gradient, reconvolution, residual, momentum, t_new, x_prev (or x_k as used in research).

2. **python/src/catune/_io.py**: Two functions:

   `save_for_tuning(traces, fs, path, metadata=None) -> None`:
   - Coerce to Float64, C-contiguous via np.ascontiguousarray(traces, dtype=np.float64)
   - If 1D, reshape to (1, -1)
   - Save as {path}.npy via np.save()
   - Create {path}_metadata.json with: schema_version "1.0.0", sampling_rate_hz, num_cells, num_timepoints, dtype "<f8", plus any user metadata
   - Use json.dump with indent=2

   `load_tuning_data(path) -> tuple[np.ndarray, dict]`:
   - Load {path}.npy via np.load()
   - Load {path}_metadata.json via json.load()
   - Return (traces, metadata) tuple
   - Raise FileNotFoundError with clear message if either file missing

3. **python/src/catune/__init__.py**: Update to export all public API:
   ```python
   from ._kernel import build_kernel, tau_to_ar2, compute_lipschitz
   from ._fista import run_deconvolution
   from ._io import save_for_tuning, load_tuning_data
   __version__ = "0.1.0"
   __all__ = [
       "build_kernel", "tau_to_ar2", "compute_lipschitz",
       "run_deconvolution", "save_for_tuning", "load_tuning_data",
   ]
   ```

All functions must have numpy-style docstrings.
  </action>
  <verify>
1. `cd /home/daharoni/dev/CaTune/python && python3 -c "from catune import run_deconvolution, save_for_tuning, load_tuning_data; print('all imports OK')"`
2. Quick smoke test:
   ```
   python3 -c "
   import numpy as np
   from catune import run_deconvolution, build_kernel
   kernel = build_kernel(0.02, 0.4, 30.0)
   trace = np.zeros(200)
   trace[50] = 1.0
   trace = np.convolve(trace, kernel)[:200]
   spikes = run_deconvolution(trace, 30.0, 0.02, 0.4, 0.01)
   print(f'shape={spikes.shape}, max={spikes.max():.4f}, min={spikes.min():.4f}, non_neg={np.all(spikes >= 0)}')
   "
   ```
   Should show non_neg=True and a spike near index 50.
  </verify>
  <done>
_fista.py implements run_deconvolution matching Rust algorithm exactly. _io.py implements save_for_tuning and load_tuning_data. __init__.py exports complete public API. All functions importable and produce expected output shapes.
  </done>
</task>

<task type="auto">
  <name>Task 2: Write comprehensive tests for solver, I/O, and cross-language equivalence</name>
  <files>
    python/tests/test_fista.py
    python/tests/test_io.py
    python/tests/test_equivalence.py
  </files>
  <action>
1. **python/tests/test_fista.py**: Mirror Rust fista.rs tests 1-8, plus additional Python-specific tests:

   - `test_delta_impulse_recovery()`: Trace = kernel (single spike at t=0). Solution should have max near t=0..2, spike > 0.1, sum of others < spike. Use tau_rise=0.02, tau_decay=0.4, lam=0.001, fs=30.0 (low lambda for clean recovery). Matches Rust test 1.

   - `test_zero_trace_produces_zero_solution()`: All-zero trace (100 samples). Solution max < 1e-10. Matches Rust test 2.

   - `test_convergence_within_max_iters()`: Synthetic trace with 4 spikes at t=10,50,100,150 (n=200). Should converge within 2000 iterations (default). Just verify solution is non-negative and has energy near spike locations. Matches Rust test 3.

   - `test_solution_non_negative()`: Trace with 3 spikes + sine noise. All solution values >= 0. Matches Rust test 4.

   - `test_deterministic_output()`: Two runs with identical inputs produce identical output (max diff < 1e-15). Matches Rust test 5.

   - `test_reconvolution_quality()`: Low lambda (0.001), 4-spike synthetic trace. Compute reconvolution = convolve(solution, kernel)[:n]. Relative error ||trace - reconv||/||trace|| < 0.1. Matches Rust test 6.

   - `test_single_trace_1d_input()`: Pass 1D array, get 1D array back.
   - `test_multi_trace_2d_input()`: Pass (3, 200) array, get (3, 200) back. Each row processed independently.
   - `test_various_parameter_sets()`: Run with fast (tau_r=0.005, tau_d=0.1) and slow (tau_r=0.05, tau_d=1.0) kinetics. Verify non-negative, converges.
   - `test_high_lambda_suppresses_spikes()`: High lambda (1.0) should produce near-zero solution even with large signal.
   - `test_short_trace()`: 10-sample trace. Should not crash, produce valid output.

   Helper function `make_synthetic_trace(kernel, n, spike_locs)` to generate test traces by convolving spikes with kernel. Define in the test file.

2. **python/tests/test_io.py**: Round-trip and format tests:

   - `test_save_load_roundtrip(tmp_path)`: Save random (5, 1000) array, load back, assert_allclose.
   - `test_save_creates_npy_and_json(tmp_path)`: Verify both files exist after save.
   - `test_metadata_contains_required_fields(tmp_path)`: Check schema_version, sampling_rate_hz, num_cells, num_timepoints, dtype in metadata JSON.
   - `test_custom_metadata_preserved(tmp_path)`: Pass metadata={"indicator": "GCaMP7f"}, verify in loaded metadata.
   - `test_1d_input_becomes_2d(tmp_path)`: Save 1D array, load back, verify shape is (1, n).
   - `test_float64_enforcement(tmp_path)`: Save float32 array, load back, verify dtype is float64.
   - `test_c_contiguous_enforcement(tmp_path)`: Save Fortran-order array, load back, verify C-contiguous.
   - `test_load_missing_file_raises(tmp_path)`: Attempt load from nonexistent path, expect FileNotFoundError.
   - `test_npy_format_compatible()`: Verify saved .npy file has fortran_order=False and dtype='<f8' by inspecting with np.lib.format.read_magic and header parsing (or just np.load and check).

3. **python/tests/test_equivalence.py**: End-to-end cross-language equivalence:

   The key insight: since we cannot easily call the Rust solver from Python in CI, we use "self-consistency" tests that verify the Python implementation satisfies the same mathematical properties the Rust tests verify. The numerical values should match because both use IEEE 754 Float64 with the same algorithm.

   - `test_kernel_equivalence_across_params()`: For 5+ parameter sets, verify kernel properties (peak=1, first=0, non-negative, length scaling). These are the same properties Rust tests verify.

   - `test_solver_self_consistency()`: Create trace = convolve(spikes, kernel). Run solver. Verify reconvolution = convolve(solution, kernel) approximates original trace (relative error < 5%). This is the fundamental contract.

   - `test_save_load_solve_pipeline()`: Full pipeline test (tmp_path):
     a. Generate synthetic traces (3 cells)
     b. save_for_tuning()
     c. load_tuning_data()
     d. run_deconvolution() on loaded data
     e. Verify solutions are non-negative and have expected spike locations

   - `test_objective_decreases_monotonically()`: Implement a version of run_deconvolution that tracks objective per iteration (or copy the inner loop). Verify objective is non-increasing after the first 5 iterations (accounting for adaptive restart). This validates the FISTA convergence guarantee.

   - `test_adjoint_is_transpose_of_forward()`: Numerical verification that the adjoint convolution is the matrix transpose of the forward convolution. For small n (say n=8, klen=3):
     Construct the forward convolution matrix K explicitly.
     Verify K^T @ residual matches _convolve_adjoint(kernel, residual).
     This catches the #1 pitfall (wrong truncation).

   Use numpy.testing.assert_allclose with rtol=1e-10 for all numerical comparisons.
  </action>
  <verify>
`cd /home/daharoni/dev/CaTune/python && python3 -m pytest tests/ -v` -- ALL tests pass (kernel + fista + io + equivalence)
  </verify>
  <done>
test_fista.py has 11+ tests covering all solver properties (matching Rust test coverage). test_io.py has 9+ round-trip and format tests. test_equivalence.py has 5+ end-to-end tests including adjoint verification. All tests pass. Complete catune package with full test suite ready for publishing.
  </done>
</task>

</tasks>

<verification>
1. `cd /home/daharoni/dev/CaTune/python && python3 -m pytest tests/ -v --tb=short` -- all tests pass
2. `python3 -c "from catune import run_deconvolution, save_for_tuning; print('PYTH-01 + PYTH-02 complete')"` -- imports succeed
3. Full pipeline smoke test:
   ```python
   python3 -c "
   import numpy as np
   from catune import save_for_tuning, load_tuning_data, run_deconvolution, build_kernel
   # Generate test data
   kernel = build_kernel(0.02, 0.4, 30.0)
   traces = np.zeros((3, 500))
   for i, loc in enumerate([100, 200, 300]):
       traces[i] = np.convolve(np.eye(1, 500, loc).ravel(), kernel)[:500]
   # Save
   save_for_tuning(traces, 30.0, '/tmp/catune_test')
   # Load
   loaded, meta = load_tuning_data('/tmp/catune_test')
   # Solve
   spikes = run_deconvolution(loaded, 30.0, 0.02, 0.4, 0.01)
   print(f'shape={spikes.shape}, all_non_neg={np.all(spikes>=0)}, meta_version={meta[\"schema_version\"]}')
   "
   ```
   Should print shape=(3, 500), all_non_neg=True, meta_version=1.0.0
</verification>

<success_criteria>
- run_deconvolution produces non-negative spike estimates matching Rust algorithm
- save_for_tuning creates .npy + _metadata.json in CaTune-compatible format
- load_tuning_data round-trips correctly
- 25+ total tests pass across all test files
- Complete public API: build_kernel, tau_to_ar2, compute_lipschitz, run_deconvolution, save_for_tuning, load_tuning_data
- PYTH-01 and PYTH-02 requirements satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/08-python-companion/08-02-SUMMARY.md`
</output>
